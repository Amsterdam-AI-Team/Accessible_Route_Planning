{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1077e83e-756f-40aa-b041-c811f0f52ae7",
      "metadata": {},
      "source": [
        "# 5. Ground and road fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4489f95-98a5-4ed2-87e7-36a0554960a2",
      "metadata": {
        "gather": {
          "logged": 1705336865303
        }
      },
      "outputs": [],
      "source": [
        "# Standard library and path imports\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Third-party library imports\n",
        "from upcp.pipeline import Pipeline\n",
        "from upcp.labels import Labels\n",
        "import upcp.fusion as fusion\n",
        "import upcp.utils.ahn_utils as ahn_utils\n",
        "import upcp.utils.bgt_utils as bgt_utils\n",
        "import upcp.utils.las_utils as las_utils\n",
        "import upcp.utils.log_utils as log_utils\n",
        "import upcp.utils.csv_utils as csv_utils\n",
        "import upcp.scrapers.ams_bgt_scraper as ams_bgt_scraper\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# Local or project-specific imports\n",
        "import settings as st\n",
        "\n",
        "if st.my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif st.my_run == \"local\":\n",
        "    import config as cf\n",
        "\n",
        "# INFO messages will be printed to console.\n",
        "log_utils.reset_logger()\n",
        "log_utils.add_console_logger(level=logging.DEBUG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64698ca6",
      "metadata": {},
      "source": [
        "## Select area to label point clouds for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a576f879",
      "metadata": {
        "gather": {
          "logged": 1705336868739
        }
      },
      "outputs": [],
      "source": [
        "# Import areas\n",
        "df_areas = gpd.read_file(cf.output_pilot_area)\n",
        "polygon = df_areas.to_crs(crs=st.CRS).unary_union"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c90e862",
      "metadata": {},
      "source": [
        "## Collect point clouds in area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2697344e",
      "metadata": {
        "gather": {
          "logged": 1705336897346
        }
      },
      "outputs": [],
      "source": [
        "# If running via Azure, mount to Azure point cloud storage here\n",
        "ahn_in_folder = cf.ahn_folder\n",
        "bgt_in_folder = cf.bgt_folder\n",
        "in_folder_point_clouds = cf.in_folder_point_clouds\n",
        "out_folder_point_clouds = cf.out_folder_point_clouds\n",
        "\n",
        "for path in [bgt_in_folder, out_folder_point_clouds]:\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1516c3b-e24e-4566-887b-ba814c8a9901",
      "metadata": {
        "gather": {
          "logged": 1705336910351
        }
      },
      "outputs": [],
      "source": [
        "# Collect all tiles in polygon area\n",
        "all_pc_filenames = []\n",
        "for path, subdirs, files in os.walk(in_folder_point_clouds):\n",
        "    for name in files:\n",
        "            if '.laz' in name:\n",
        "                all_pc_filenames.append(os.path.join(path, name))\n",
        "all_pc_filenames = np.array(all_pc_filenames)\n",
        "all_pc_tilecodes = np.array([las_utils.get_tilecode_from_filename(filename) for filename in all_pc_filenames])\n",
        "all_pc_bboxes = np.array([las_utils.get_bbox_from_tile_code(tilecode) for tilecode in all_pc_tilecodes])\n",
        "\n",
        "all_pc_polygons = [las_utils.get_polygon_from_tile_code(tilecode) for tilecode in all_pc_tilecodes]\n",
        "gdf_pc_polygons = gpd.GeoDataFrame(geometry=all_pc_polygons)\n",
        "\n",
        "gdf = gdf_pc_polygons.intersection(polygon)\n",
        "pc_idxs_in_area_polygon = gdf[~gdf.is_empty].index.to_list()\n",
        "\n",
        "# filenames, tilecodes and bounding boxes of point clouds in selected area\n",
        "pc_filenames = all_pc_filenames[pc_idxs_in_area_polygon]\n",
        "pc_tilecodes = all_pc_tilecodes[pc_idxs_in_area_polygon]\n",
        "pc_bboxes = all_pc_bboxes[pc_idxs_in_area_polygon]\n",
        "\n",
        "sns.set()\n",
        "ax = gdf_pc_polygons.iloc[pc_idxs_in_area_polygon].boundary.plot()\n",
        "ax = df_areas.boundary.plot(ax=ax)\n",
        "plt.title('Point clouds in selected area')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d5299a-1ac2-4a63-949a-ff1ce2b77eb2",
      "metadata": {},
      "source": [
        "## Ground and building fuser using pre-processed BGT and AHN data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c17bd44",
      "metadata": {
        "gather": {
          "logged": 1705336938385
        }
      },
      "outputs": [],
      "source": [
        "# Write all BGT files for tiles in selected area if they do not already exist. \n",
        "# If cell is interupted due to too many api requests, restart kernel and run all cells again to infer missing BGT files.\n",
        "for pc_tilecode, pc_bbox in tqdm(zip(pc_tilecodes, pc_bboxes), total=len(pc_tilecodes)):\n",
        "\n",
        "    # Output file for the BGT fuser.\n",
        "    bgt_data_file = bgt_in_folder + '{}.csv'.format(pc_tilecode)\n",
        "    if not os.path.isfile(bgt_data_file):\n",
        "        csv_headers = ['bgt_name', 'polygon', 'x_min', 'y_max', 'x_max', 'y_min']\n",
        "            \n",
        "        # Road and parking spots layers in BGT\n",
        "        bgt_layers = ['BGT_WGL_rijbaan_lokale_weg', 'BGT_WGL_rijbaan_regionale_weg',\n",
        "                    'BGT_WGL_rijbaan_autoweg', 'BGT_WGL_rijbaan_autosnelweg',\n",
        "                    'BGT_WGL_parkeervlak', 'BGT_WGL_ov-baan', 'BGT_WGL_fietspad']\n",
        "\n",
        "        # Scrape data from the Amsterdam WFS and parse the json.\n",
        "        bgt_road_polygons_csv = []\n",
        "        for layer in bgt_layers:\n",
        "            # Scrape data from the Amsterdam WFS, this will return a json response.\n",
        "            json_content = ams_bgt_scraper.scrape_amsterdam_bgt(layer, bbox=pc_bbox)\n",
        "            \n",
        "            # Parse the downloaded json response.\n",
        "            parsed_content = ams_bgt_scraper.parse_polygons(json_content)\n",
        "            bgt_road_polygons_csv += parsed_content\n",
        "\n",
        "        # Write the csv\n",
        "        csv_utils.write_csv(bgt_data_file, bgt_road_polygons_csv, csv_headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92102ce0-e172-4ac0-8b2d-53540df41acc",
      "metadata": {
        "gather": {
          "logged": 1705336973317
        }
      },
      "outputs": [],
      "source": [
        "# Create the reader for .npz data.\n",
        "npz_reader = ahn_utils.NPZReader(ahn_in_folder)\n",
        "\n",
        "# Label point clouds\n",
        "for tilecode, filename in tqdm(zip(pc_tilecodes, pc_filenames), total=len(pc_tilecodes)):\n",
        "\n",
        "    # get file directories\n",
        "    bgt_road_file = bgt_in_folder + tilecode + '.csv'\n",
        "    pc_in_file = filename \n",
        "    pc_out_file = out_folder_point_clouds + 'road_ground_labeled_' + tilecode + '.laz'\n",
        "    if not os.path.isfile(pc_out_file):\n",
        "\n",
        "        # Create reader for BGT road part polygons.\n",
        "        bgt_road_reader = bgt_utils.BGTPolyReader(bgt_file=bgt_road_file)\n",
        "\n",
        "        # Create fusers\n",
        "        params = {'bottom': 0., 'buffer': 0.02}\n",
        "        npz_ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_reader=npz_reader,\n",
        "                                    target='ground', epsilon=0.2, params=params)\n",
        "        road_part_fuser = fusion.BGTRoadFuser(Labels.ROAD, bgt_reader=bgt_road_reader)\n",
        "\n",
        "        # Pipeline to label ground and road \n",
        "        process_sequence = (npz_ground_fuser, road_part_fuser)\n",
        "        pipeline = Pipeline(processors=process_sequence, caching=False)\n",
        "\n",
        "        # Process the file.\n",
        "        pipeline.process_file(pc_in_file, out_file=pc_out_file)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "curb_exploration"
    },
    "kernelspec": {
      "display_name": "route_planner",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
